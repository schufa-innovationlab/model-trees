{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Regressors\n",
    "This notebook compares multiple regression methods on multiple datasets and evaluates them in terms of the $r^2$-measure.\n",
    "\n",
    "__Note:__ There is a similar [notebook for classification datasets](Comparing_Classifiers.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import r2_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "try:\n",
    "    # Model Trees are installed / on the path\n",
    "    from modeltrees import ModelTreeRegressor\n",
    "except:\n",
    "    # Assume project structure\n",
    "    import sys\n",
    "    sys.path.append(\"..\")\n",
    "    from modeltrees import ModelTreeRegressor\n",
    "from modeltrees.criteria import SumOfSquareErrorSplitCriterion\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Downloading and accessing files\n",
    "import shutil\n",
    "import urllib.request\n",
    "from urllib.parse import urlparse\n",
    "from pathlib import Path\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datasets\n",
    "In this section, all datasets for the comparison are defined. Missing datasets are downloaded automatically.\n",
    "\n",
    "See [Section 3.3](#characteristics) for a list of dataset characteristics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Downloading Datasets\n",
    "We do not ship datasets with this repository, but the notebook will automatically try to download missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"./data\"\n",
    "\n",
    "def get_dataset_file_path(dataset_id, url, file=None):\n",
    "    # If no file is specified, take the name from the url\n",
    "    if file is None:\n",
    "        file = urlparse(url)\n",
    "        file = os.path.basename(file.path)\n",
    "     \n",
    "    # Create path to local file\n",
    "    path = Path(data_path, dataset_id, file)\n",
    "    \n",
    "    if not path.exists():\n",
    "        # Create missing folders\n",
    "        os.makedirs(path.parent, exist_ok=True)\n",
    "        \n",
    "        # Download missing file\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            with open(path, \"wb\") as outputFile:\n",
    "                shutil.copyfileobj(response, outputFile)\n",
    "    \n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Dataset Definitions\n",
    "The following defines different datasets with their download url, and possibly some preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_beijing_pm25():\n",
    "    # Dataset name and source\n",
    "    ds_name = \"beijing_pm25\"\n",
    "    url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00381/PRSA_data_2010.1.1-2014.12.31.csv\"\n",
    "    \n",
    "    # Load csv file\n",
    "    path = get_dataset_file_path(ds_name, url)\n",
    "    df = pd.read_csv(path, index_col=0)\n",
    "    \n",
    "    # Filter NAN and inf in target variable\n",
    "    df = df[np.isfinite(df[\"pm2.5\"])]\n",
    "    \n",
    "    # Get Target variable\n",
    "    y = df[\"pm2.5\"].values\n",
    "    df.drop(columns=\"pm2.5\", inplace=True)\n",
    "    \n",
    "    # Preprocess Features\n",
    "    #    One-Hot Encoding of categorical variable\n",
    "    df = pd.get_dummies(df, columns=[\"cbwd\"])\n",
    "    \n",
    "    # Get Features\n",
    "    X = df.values\n",
    "    \n",
    "    return X, y, {'ref':'https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Iterating over all Datasets\n",
    "This gives a generator that iterates over all datasets.  \n",
    "Each dataset is a triple consisting of \n",
    "- Features Matrix `X`, \n",
    "- Target Vector `y`, and \n",
    "- An attribute dictionary that contains meta information like the name of the dataset or a reference url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    # Using generators instead of lists for memory efficiency reasons.\n",
    "    \n",
    "    # Dataset 1: California Housing\n",
    "    data = fetch_california_housing()\n",
    "    X = data.data\n",
    "    y = data.target\n",
    "    attr = {       # Attributes\n",
    "        'name': 'Cal. Housing',\n",
    "        'ref': 'https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset'\n",
    "    }   \n",
    "    \n",
    "    yield (X, y, attr)\n",
    "    \n",
    "    # Dataset 2: Beijing PM2.5\n",
    "    X, y, attr = fetch_beijing_pm25()\n",
    "    attr['name'] = 'Beijing PM2.5'\n",
    "    yield (X, y, attr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Regressors\n",
    "We are comparing the following regressors:\n",
    "- Linear Regression\n",
    "- Decision Trees with maximal depth 3 and 6 \n",
    "- Model Trees with maximal depth 1 and 3. We compare two split criteria:\n",
    "    - Plain Gradients \n",
    "    - Renormalized Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regressors():\n",
    "    # Create custom criterion\n",
    "    sse = SumOfSquareErrorSplitCriterion()\n",
    "    return [\n",
    "        (LinearRegression(normalize = True), \"Lin. Reg.\"),\n",
    "        (DecisionTreeRegressor(max_depth=3, random_state=12), \"Decision Tree\"),\n",
    "        (DecisionTreeRegressor(max_depth=6, random_state=12), \"Decision Tree\"),\n",
    "        (ModelTreeRegressor(max_depth=1, criterion=sse), \"Model Tree (SSE)\"),\n",
    "        (ModelTreeRegressor(max_depth=3, criterion=sse), \"Model Tree (SSE)\"),\n",
    "        (ModelTreeRegressor(max_depth=1), \"Model Tree (Gradient)\"),\n",
    "        (ModelTreeRegressor(max_depth=3), \"Model Tree (Gradient)\"),\n",
    "        (ModelTreeRegressor(max_depth=1, criterion=\"gradient-renorm-z\"), \"Model Tree (Renorm. Gradient)\"),\n",
    "        (ModelTreeRegressor(max_depth=3, criterion=\"gradient-renorm-z\"), \"Model Tree (Renorm. Gradient)\")\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparison\n",
    "### 3.1 Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross Validation: Number of Folds\n",
    "n_fold = 5\n",
    "\n",
    "seed = 42   # We suggest to try other values to get a feeling for the stability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Evaluation\n",
    "Iterating over datasets and regressors and evaluating the regressors in terms of the $r^2$ metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for results (see 3.4)\n",
    "# Multi-Index for better readability\n",
    "col_index = pd.MultiIndex(levels=[[],[]],\n",
    "                             codes=[[],[]],\n",
    "                             names=['Method', 'Depth'])\n",
    "results = pd.DataFrame(columns=col_index)\n",
    "\n",
    "# Create a DataFrame for the Dataset Characteristics (see 3.3)\n",
    "ds_characteristics = pd.DataFrame(columns=(\"#Samples\", \"#Features\", \"Reference\"))\n",
    "\n",
    "# Create a scorer function\n",
    "scorer = make_scorer(r2_score)\n",
    "\n",
    "# Iterate over Datasets\n",
    "for X, y, attr in get_datasets():\n",
    "    ds_name = attr['name']\n",
    "    \n",
    "    # Store dataset  characteristics\n",
    "    n_samples, n_features = X.shape\n",
    "    ds_characteristics.loc[ds_name, \"#Samples\"] = n_samples\n",
    "    ds_characteristics.loc[ds_name, \"#Features\"] = n_features\n",
    "    \n",
    "    if \"ref\" in attr:\n",
    "        ds_characteristics.loc[ds_name, \"Reference\"] = attr[\"ref\"]\n",
    "    else:\n",
    "        ds_characteristics.loc[ds_name, \"Reference\"] = None\n",
    "    \n",
    "    # Iterate over Regressors\n",
    "    for model, m_name in get_regressors():\n",
    "        # Use the same seed for comparing different regressors\n",
    "        kfold = KFold(n_splits=n_fold, shuffle=True, random_state=seed)\n",
    "        \n",
    "        # Compute scores of all k folds (see variable n_fold)\n",
    "        scores = cross_val_score(model, X, y, scoring=scorer, cv=kfold)\n",
    "        \n",
    "        # Compute statistics from list of scores\n",
    "        mean_score = np.mean(scores)\n",
    "        std_score = np.std(scores)\n",
    "        \n",
    "        # Create result cell\n",
    "        cell_text = f\"{mean_score*100:.2f} Â± {std_score*100:.2f}\" \n",
    "        \n",
    "        # Multi-Indexing\n",
    "        if hasattr(model, 'max_depth'):\n",
    "            col_idx = (m_name, f\"{model.max_depth}\")\n",
    "        else:\n",
    "            col_idx = (m_name, '-')\n",
    "            \n",
    "        results.loc[ds_name, col_idx] = cell_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Dataset Characteristics <a id='characteristics'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_e0babd3e_1518_11ea_822e_10e7c62ae0ed\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >#Samples</th>        <th class=\"col_heading level0 col1\" >#Features</th>        <th class=\"col_heading level0 col2\" >Reference</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_e0babd3e_1518_11ea_822e_10e7c62ae0edlevel0_row0\" class=\"row_heading level0 row0\" >Cal. Housing</th>\n",
       "                        <td id=\"T_e0babd3e_1518_11ea_822e_10e7c62ae0edrow0_col0\" class=\"data row0 col0\" >20640</td>\n",
       "                        <td id=\"T_e0babd3e_1518_11ea_822e_10e7c62ae0edrow0_col1\" class=\"data row0 col1\" >8</td>\n",
       "                        <td id=\"T_e0babd3e_1518_11ea_822e_10e7c62ae0edrow0_col2\" class=\"data row0 col2\" ><a target=\"_blank\" href=\"https://scikit-learn.org/stable/datasets/index.html#california-housing-dataset\">Link</a></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_e0babd3e_1518_11ea_822e_10e7c62ae0edlevel0_row1\" class=\"row_heading level0 row1\" >Beijing PM2.5</th>\n",
       "                        <td id=\"T_e0babd3e_1518_11ea_822e_10e7c62ae0edrow1_col0\" class=\"data row1 col0\" >41757</td>\n",
       "                        <td id=\"T_e0babd3e_1518_11ea_822e_10e7c62ae0edrow1_col1\" class=\"data row1 col1\" >14</td>\n",
       "                        <td id=\"T_e0babd3e_1518_11ea_822e_10e7c62ae0edrow1_col2\" class=\"data row1 col2\" ><a target=\"_blank\" href=\"https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data\">Link</a></td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1f936cbeb70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_characteristics[\"#Samples\"] = ds_characteristics[\"#Samples\"].astype(dtype=np.int)\n",
    "ds_characteristics[\"#Features\"] = ds_characteristics[\"#Features\"].astype(dtype=np.int)\n",
    "\n",
    "def format_link(val):\n",
    "    # Handle Empty references\n",
    "    if val is None:\n",
    "        return ''\n",
    "    \n",
    "    # Format link\n",
    "    return '<a target=\"_blank\" href=\"{}\">Link</a>'.format(val)\n",
    "\n",
    "ds_characteristics.style.format({'Reference': format_link})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Results\n",
    "The regressors are evaluated in terms of the $r^2$ metric.  \n",
    "The following results are given in percentage. The uncertainty is given as standard deviation of the $r^2$ score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Method</th>\n",
       "      <th>Lin. Reg.</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Decision Tree</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model Tree (SSE)</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model Tree (Gradient)</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Model Tree (Renorm. Gradient)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Depth</th>\n",
       "      <th>-</th>\n",
       "      <th>3</th>\n",
       "      <th>6</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "      <th>1</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Cal. Housing</th>\n",
       "      <td>60.14 Â± 1.70</td>\n",
       "      <td>52.70 Â± 1.46</td>\n",
       "      <td>64.15 Â± 1.29</td>\n",
       "      <td>49.07 Â± 24.42</td>\n",
       "      <td>62.19 Â± 9.31</td>\n",
       "      <td>67.09 Â± 1.57</td>\n",
       "      <td>68.32 Â± 1.68</td>\n",
       "      <td>67.16 Â± 1.50</td>\n",
       "      <td>72.24 Â± 1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Beijing PM2.5</th>\n",
       "      <td>27.48 Â± 0.52</td>\n",
       "      <td>21.63 Â± 1.15</td>\n",
       "      <td>38.83 Â± 0.95</td>\n",
       "      <td>31.62 Â± 0.82</td>\n",
       "      <td>37.20 Â± 0.89</td>\n",
       "      <td>31.38 Â± 0.84</td>\n",
       "      <td>47.04 Â± 1.42</td>\n",
       "      <td>35.04 Â± 0.71</td>\n",
       "      <td>50.78 Â± 1.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Method            Lin. Reg. Decision Tree               Model Tree (SSE)  \\\n",
       "Depth                     -             3             6                1   \n",
       "Cal. Housing   60.14 Â± 1.70  52.70 Â± 1.46  64.15 Â± 1.29    49.07 Â± 24.42   \n",
       "Beijing PM2.5  27.48 Â± 0.52  21.63 Â± 1.15  38.83 Â± 0.95     31.62 Â± 0.82   \n",
       "\n",
       "Method                      Model Tree (Gradient)                \\\n",
       "Depth                     3                     1             3   \n",
       "Cal. Housing   62.19 Â± 9.31          67.09 Â± 1.57  68.32 Â± 1.68   \n",
       "Beijing PM2.5  37.20 Â± 0.89          31.38 Â± 0.84  47.04 Â± 1.42   \n",
       "\n",
       "Method        Model Tree (Renorm. Gradient)                \n",
       "Depth                                     1             3  \n",
       "Cal. Housing                   67.16 Â± 1.50  72.24 Â± 1.05  \n",
       "Beijing PM2.5                  35.04 Â± 0.71  50.78 Â± 1.09  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
